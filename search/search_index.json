{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"neuropull \u00b6 A lightweight tool for pulling connectome networks and metadata Documentation: https://neurodata.github.io/neuropull GitHub: https://github.com/neurodata/neuropull PyPI: https://pypi.org/project/neuropull/ Free software: MIT Features \u00b6 TODO Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Home"},{"location":"#neuropull","text":"A lightweight tool for pulling connectome networks and metadata Documentation: https://neurodata.github.io/neuropull GitHub: https://github.com/neurodata/neuropull PyPI: https://pypi.org/project/neuropull/ Free software: MIT","title":"neuropull"},{"location":"#features","text":"TODO","title":"Features"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"::: neuropull","title":"Modules"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [0.2.0] - 2023-01-05 \u00b6 Added \u00b6 New documentation with an (incomplete) simple tutorial using the AdjacencyFrame [0.1.1] - 2023-01-05 \u00b6 Fixed \u00b6 Tried to fix bug in automatic changelog tracking on Github [0.1.0] - 2023-01-05 \u00b6 Added \u00b6 Early draft of AdjacencyFrame and related code for manipulating networks and matrices. [0.0.4] - 2022-09-21 \u00b6 Added \u00b6 First release on PyPI.","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#020-2023-01-05","text":"","title":"[0.2.0] - 2023-01-05"},{"location":"changelog/#added","text":"New documentation with an (incomplete) simple tutorial using the AdjacencyFrame","title":"Added"},{"location":"changelog/#011-2023-01-05","text":"","title":"[0.1.1] - 2023-01-05"},{"location":"changelog/#fixed","text":"Tried to fix bug in automatic changelog tracking on Github","title":"Fixed"},{"location":"changelog/#010-2023-01-05","text":"","title":"[0.1.0] - 2023-01-05"},{"location":"changelog/#added_1","text":"Early draft of AdjacencyFrame and related code for manipulating networks and matrices.","title":"Added"},{"location":"changelog/#004-2022-09-21","text":"","title":"[0.0.4] - 2022-09-21"},{"location":"changelog/#added_2","text":"First release on PyPI.","title":"Added"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/neurodata/neuropull/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 neuropull could always use more documentation, whether as part of the official neuropull docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/neurodata/neuropull/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up neuropull for local development. Fork the neuropull repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/neuropull.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/neurodata/neuropull/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 $ poetry run pytest tests/test_neuropull.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/neurodata/neuropull/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"neuropull could always use more documentation, whether as part of the official neuropull docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/neurodata/neuropull/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up neuropull for local development. Fork the neuropull repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/neuropull.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/neurodata/neuropull/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"$ poetry run pytest tests/test_neuropull.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install neuropull, run this command in your terminal: $ pip install neuropull This is the preferred method to install neuropull, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for neuropull can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/neurodata/neuropull Or download the tarball : $ curl -OJL https://github.com/neurodata/neuropull/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install neuropull, run this command in your terminal: $ pip install neuropull This is the preferred method to install neuropull, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for neuropull can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/neurodata/neuropull Or download the tarball : $ curl -OJL https://github.com/neurodata/neuropull/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 To use neuropull in a project import neuropull","title":"Usage"},{"location":"usage/#usage","text":"To use neuropull in a project import neuropull","title":"Usage"},{"location":"tutorials/maggot_examples/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Manipulating data with an AdjacencyFrame \u00b6 Examples from a maggot brain connectome dataset. Eventually this will be using neuropull itself to grab the data, instead of pulling from my computer. Load the data \u00b6 from pathlib import Path import networkx as nx import numpy as np import pandas as pd data_path = Path ( \"neuropull/processing/raw_data/maggot/2022-09-25\" ) g = nx . read_edgelist ( data_path / \"G_edgelist.txt\" , delimiter = \" \" , data = [( \"weight\" , float )], create_using = nx . DiGraph , nodetype = int , ) nodes = pd . read_csv ( data_path / \"meta_data.csv\" , index_col = 0 ) nodes = nodes [ nodes . index . isin ( g . nodes )] adj = nx . to_pandas_adjacency ( g , nodelist = nodes . index ) Load the data into an adjacency frame \u00b6 To load the data as an adjacency frame, we simply need to specify the adjacency matrix (as a pandas DataFrame) and the node data (as a pandas DataFrame). Note that the data is not copied by default, so if you modify the underlying data, this would be reflected in the adjacency frame. from neuropull.graph import AdjacencyFrame af = AdjacencyFrame ( adj . copy (), nodes . copy (), nodes . copy ()) af AdjacencyFrame with shape: (3549, 3549) Source node features: 58 Target node features: 58 Let's look at what this frame consists of. First is the adjacency matrix itself af . data array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]) This adjacency matrix is always indexed the same way as the node data. We can look at this index (for the rows) with the index attribute. af . index Int64Index([ 7766016, 7790597, 18833414, 15564807, 17383431, 7782409, 14434314, 15458316, 11018254, 11714576, ... 8142831, 12787696, 15589362, 11067379, 2637812, 3882998, 15638520, 19111930, 15679484, 16629757], dtype='int64', length=3549) And similarly for the columns via the columns attribute. af . columns Int64Index([ 7766016, 7790597, 18833414, 15564807, 17383431, 7782409, 14434314, 15458316, 11018254, 11714576, ... 8142831, 12787696, 15589362, 11067379, 2637812, 3882998, 15638520, 19111930, 15679484, 16629757], dtype='int64', length=3549) Note that here these are the same, but be aware that this need not be the case. The other components of the data are the node metadata (again, by default, potentially different for rows and columns). This is stored in row_objects and col_objects. print ( af . row_objects ) name neurons \\ 7766016 H-shaped _a1l False 7790597 vchA/B a1l False 18833414 MN-R-Sens-B2-VM-23 False 15564807 AN-R-Sens-B1-AVa-22 False 17383431 BAlp_ant ascending dendrite left True ... ... ... 3882998 CP contra to SEZ left; MB1: incomplete neuron ... True 15638520 MN-R-Sens-B3-VM-06 False 19111930 MN13 ISN MN-VL2_a1l False 15679484 MN-L-Sens-B2-VM-08 False 16629757 KC no pair True paper_clustered_neurons left right center sink \\ 7766016 True True False False False 7790597 False True False False False 18833414 True False True False False 15564807 True False True False False 17383431 True True False False False ... ... ... ... ... ... 3882998 True True False False False 15638520 True False True False False 19111930 False True False False False 15679484 True True False False False 16629757 True True False False False partially_differentiated unsplittable ipsilateral_axon ... \\ 7766016 False False False ... 7790597 False False False ... 18833414 False False False ... 15564807 False False True ... 17383431 False False True ... ... ... ... ... ... 3882998 False False False ... 15638520 False False True ... 19111930 False False False ... 15679484 False False True ... 16629757 False False True ... n_simple_groups color hemisphere pair pair_id lineage \\ 7766016 1 #A0DDF2 L 10937355 1473 unk 7790597 0 #ACAAC8 L 7746883 1240 unk 18833414 1 #00753F R 15699715 1535 unk 15564807 1 #00753F R 1414206 1628 unk 17383431 1 #E0B1AD L 9532295 962 BAlp_ant_l ... ... ... ... ... ... ... 3882998 1 #D88052 L 11261332 1149 CPe_l 15638520 1 #00753F R 15724520 1550 unk 19111930 0 #ACAAC8 L 14194703 1361 unk 15679484 1 #00753F L 15610387 1525 unk 16629757 1 #E55560 L -1 -1 MBNB A axon_output axon_input dendrite_output dendrite_input 7766016 402.0 73.0 27.0 200.0 7790597 283.0 17.0 0.0 0.0 18833414 315.0 40.0 0.0 0.0 15564807 117.0 14.0 0.0 0.0 17383431 147.0 11.0 48.0 47.0 ... ... ... ... ... 3882998 104.0 7.0 1.0 21.0 15638520 155.0 24.0 0.0 0.0 19111930 0.0 0.0 0.0 194.0 15679484 116.0 5.0 0.0 0.0 16629757 199.0 76.0 34.0 67.0 [3549 rows x 58 columns] Sorting \u00b6 We can sort the adjacency matrix and metadata according to some attributes. For example, alphabetically by name: sorted_af = af . sort_values ( \"name\" , axis = \"both\" ) print ( sorted_af . row_objects . head () . iloc [:, : 5 ]) name neurons \\ 7753261 (dda E3 or dda A)_a1l_JMpair2 False 3486867 130729_SFO Cand 42a-42b_OSN_IN1 left True 5478818 130729_SFO Cand 42a-42b_OSN_IN1 right True 7527710 13a ORN left False 4073353 13a ORN right False paper_clustered_neurons left right 7753261 False True False 3486867 True True False 5478818 True False True 7527710 True True False 4073353 True False True ... or by the amount of incoming synapses onto the dendrite: sorted_af = af . sort_values ( \"dendrite_input\" , axis = \"both\" , ascending = False ) print ( sorted_af . row_objects . head ()[[ \"name\" , \"dendrite_input\" ]]) name dendrite_input 8980589 MBE18 right 1481.0 16223537 MBE18 left 1282.0 8198238 broad T2 right 1201.0 5030808 keystone left 1129.0 6557581 broad T3 right 1127.0 In any case, the adjacency matrix is always sorted the same way as the metadata. from graspologic.plot import adjplot # adjplot(af.data, plot_type=\"scattermap\", sizes=(1, 1)) # adjplot(sorted_af.data, plot_type=\"scattermap\", sizes=(1, 1)) /Users/bpedigo/JHU_code/neuropull/neuropull/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html from .autonotebook import tqdm as notebook_tqdm Filtering and subsetting \u00b6 We can filter the adjacency matrix and metadata according to some attributes. For example, we could select only the nodes in the left hemisphere. query_af = af . query ( \"hemisphere == 'L'\" , axis = \"both\" ) print ( query_af ) AdjacencyFrame with shape: (1772, 1772) Source node features: 58 Target node features: 58 Note that since the adjacency frame is just a thin wrapper around pandas DataFrames, we can use all the usual pandas methods to filter the data. For example, we can select only the nodes that are in the left hemisphere and have a dendrite input greater than some threshold. query_af = af . query ( \"hemisphere == 'L' and dendrite_input > 100\" , axis = \"both\" ) print ( query_af ) AdjacencyFrame with shape: (608, 608) Source node features: 58 Target node features: 58 We can also select a non-induced subgraph: that is, a set of edges that go from one set of nodes to a potentially different set of target nodes. Here, we select the connections from the left hemisphere to the right hemisphere. query_af = af . query ( \"hemisphere == 'L'\" , axis = 0 ) . query ( \"hemisphere == 'R'\" , axis = 1 ) print ( query_af . source_nodes [ \"hemisphere\" ]) print ( query_af . target_nodes [ \"hemisphere\" ]) 7766016 L 7790597 L 17383431 L 7782409 L 14434314 L .. 11067379 L 3882998 L 19111930 L 15679484 L 16629757 L Name: hemisphere, Length: 1772, dtype: object 18833414 R 15564807 R 15458316 R 11714576 R 10133525 R .. 15564782 R 12787696 R 15589362 R 2637812 R 15638520 R Name: hemisphere, Length: 1775, dtype: object Grouping \u00b6 Rather than selecting groups of nodes (like, say, the left hemisphere) one at a time, it is often convenient to subselect the entire network based on some column. First, let's remove a couple of nodes which are in the center (not on left or right). af = af . query ( \"hemisphere != 'C'\" , axis = \"both\" ) Then, let's do a grouping operation. groupby = af . groupby ( \"hemisphere\" , axis = \"both\" ) groupby <neuropull.graph.base_frame.FrameGroupBy at 0x13d1fc880> Much like in pandas, this returns a GroupBy object, which can be iterated over. for name , subframe in groupby : print ( name ) print ( subframe ) ('L', 'L') AdjacencyFrame with shape: (1772, 1772) Source node features: 58 Target node features: 58 ('L', 'R') AdjacencyFrame with shape: (1772, 1775) Source node features: 58 Target node features: 58 ('R', 'L') AdjacencyFrame with shape: (1775, 1772) Source node features: 58 Target node features: 58 ('R', 'R') AdjacencyFrame with shape: (1775, 1775) Source node features: 58 Target node features: 58 We could, for instance, compute the number of possible edges in each group. def possible_edges ( frame ): return frame . shape [ 0 ] * frame . shape [ 1 ] for name , subframe in groupby : print ( name ) print ( \"Possible edges:\" , possible_edges ( subframe )) print () ('L', 'L') Possible edges: 3139984 ('L', 'R') Possible edges: 3145300 ('R', 'L') Possible edges: 3145300 ('R', 'R') Possible edges: 3150625 Just like in pandas, since this pattern is so common, we can use the apply function of the FrameGroupBy object to apply a function to each group and collate the results. groupby . apply ( possible_edges ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 3139984 3145300 R 3145300 3150625 If we want to use a function which operates on the underlying adjacency matrix only, we can just modify the function slightly. def matrix_sum ( frame ): return np . sum ( frame . data ) groupby . apply ( matrix_sum ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 123720.0 58409.0 R 54783.0 136440.0 However, shorthand for this is to just pass the data=True flag to the apply function, and then a function which operates on the adjacency matrix will work. groupby . apply ( np . sum , data = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 123720.0 58409.0 R 54783.0 136440.0 Another example is using this to compute the probability of an edge existing between each group. def density ( data ): return np . count_nonzero ( data ) / data . size groupby . apply ( density , data = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 0.01238 0.006056 R 0.00588 0.013209 pair_counts = af . source_nodes [ \"pair_id\" ] . value_counts () af . source_nodes [ \"pair_count\" ] = af . source_nodes [ \"pair_id\" ] . map ( pair_counts ) == 2 af . target_nodes [ \"pair_count\" ] = af . target_nodes [ \"pair_id\" ] . map ( pair_counts ) == 2 pair_af = af . query ( \"pair_count\" , axis = \"both\" ) pair_af = pair_af . sort_values ([ \"hemisphere\" , \"pair_id\" ], axis = \"both\" ) pair_af = pair_af . set_index ([ \"hemisphere\" , \"pair_id\" ]) print ( pair_af . source_nodes . iloc [: 5 , : 5 ]) name neurons \\ hemisphere pair_id L 2 BAmas12 contra left; Interneuron--35 in total True 3 DALd bushy left; DALd_l 2 True 4 DALd_l 3 True 5 BU ; DALd 4_left True 6 UNK brain ascending left True paper_clustered_neurons left right hemisphere pair_id L 2 True True False 3 True True False 4 True True False 5 True True False 6 True True False print ( pair_af . source_nodes . loc [ \"L\" ] . iloc [: 5 , : 5 ]) name neurons \\ pair_id 2 BAmas12 contra left; Interneuron--35 in total True 3 DALd bushy left; DALd_l 2 True 4 DALd_l 3 True 5 BU ; DALd 4_left True 6 UNK brain ascending left True paper_clustered_neurons left right pair_id 2 True True False 3 True True False 4 True True False 5 True True False 6 True True False print ( pair_af . source_nodes . loc [ \"R\" ] . iloc [: 5 , : 5 ]) name neurons paper_clustered_neurons \\ pair_id 2 BAmas12 contra right True True 3 DALd bushy right; DALd_r 5 Review True True 4 DALd_r 10 10276162 - JL True True 5 BU ; DALd 4_right True True 6 UNK brain ascending right True True left right pair_id 2 False True 3 False True 4 False True 5 False True 6 False True for hemisphere , side_af in pair_af . groupby ( \"hemisphere\" , axis = \"both\" ): print ( hemisphere ) print ( side_af ) ('L', 'L') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57 ('L', 'R') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57 ('R', 'L') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57 ('R', 'R') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57","title":"Maggot examples"},{"location":"tutorials/maggot_examples/#manipulating-data-with-an-adjacencyframe","text":"Examples from a maggot brain connectome dataset. Eventually this will be using neuropull itself to grab the data, instead of pulling from my computer.","title":"Manipulating data with an AdjacencyFrame"},{"location":"tutorials/maggot_examples/#load-the-data","text":"from pathlib import Path import networkx as nx import numpy as np import pandas as pd data_path = Path ( \"neuropull/processing/raw_data/maggot/2022-09-25\" ) g = nx . read_edgelist ( data_path / \"G_edgelist.txt\" , delimiter = \" \" , data = [( \"weight\" , float )], create_using = nx . DiGraph , nodetype = int , ) nodes = pd . read_csv ( data_path / \"meta_data.csv\" , index_col = 0 ) nodes = nodes [ nodes . index . isin ( g . nodes )] adj = nx . to_pandas_adjacency ( g , nodelist = nodes . index )","title":"Load the data"},{"location":"tutorials/maggot_examples/#load-the-data-into-an-adjacency-frame","text":"To load the data as an adjacency frame, we simply need to specify the adjacency matrix (as a pandas DataFrame) and the node data (as a pandas DataFrame). Note that the data is not copied by default, so if you modify the underlying data, this would be reflected in the adjacency frame. from neuropull.graph import AdjacencyFrame af = AdjacencyFrame ( adj . copy (), nodes . copy (), nodes . copy ()) af AdjacencyFrame with shape: (3549, 3549) Source node features: 58 Target node features: 58 Let's look at what this frame consists of. First is the adjacency matrix itself af . data array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]) This adjacency matrix is always indexed the same way as the node data. We can look at this index (for the rows) with the index attribute. af . index Int64Index([ 7766016, 7790597, 18833414, 15564807, 17383431, 7782409, 14434314, 15458316, 11018254, 11714576, ... 8142831, 12787696, 15589362, 11067379, 2637812, 3882998, 15638520, 19111930, 15679484, 16629757], dtype='int64', length=3549) And similarly for the columns via the columns attribute. af . columns Int64Index([ 7766016, 7790597, 18833414, 15564807, 17383431, 7782409, 14434314, 15458316, 11018254, 11714576, ... 8142831, 12787696, 15589362, 11067379, 2637812, 3882998, 15638520, 19111930, 15679484, 16629757], dtype='int64', length=3549) Note that here these are the same, but be aware that this need not be the case. The other components of the data are the node metadata (again, by default, potentially different for rows and columns). This is stored in row_objects and col_objects. print ( af . row_objects ) name neurons \\ 7766016 H-shaped _a1l False 7790597 vchA/B a1l False 18833414 MN-R-Sens-B2-VM-23 False 15564807 AN-R-Sens-B1-AVa-22 False 17383431 BAlp_ant ascending dendrite left True ... ... ... 3882998 CP contra to SEZ left; MB1: incomplete neuron ... True 15638520 MN-R-Sens-B3-VM-06 False 19111930 MN13 ISN MN-VL2_a1l False 15679484 MN-L-Sens-B2-VM-08 False 16629757 KC no pair True paper_clustered_neurons left right center sink \\ 7766016 True True False False False 7790597 False True False False False 18833414 True False True False False 15564807 True False True False False 17383431 True True False False False ... ... ... ... ... ... 3882998 True True False False False 15638520 True False True False False 19111930 False True False False False 15679484 True True False False False 16629757 True True False False False partially_differentiated unsplittable ipsilateral_axon ... \\ 7766016 False False False ... 7790597 False False False ... 18833414 False False False ... 15564807 False False True ... 17383431 False False True ... ... ... ... ... ... 3882998 False False False ... 15638520 False False True ... 19111930 False False False ... 15679484 False False True ... 16629757 False False True ... n_simple_groups color hemisphere pair pair_id lineage \\ 7766016 1 #A0DDF2 L 10937355 1473 unk 7790597 0 #ACAAC8 L 7746883 1240 unk 18833414 1 #00753F R 15699715 1535 unk 15564807 1 #00753F R 1414206 1628 unk 17383431 1 #E0B1AD L 9532295 962 BAlp_ant_l ... ... ... ... ... ... ... 3882998 1 #D88052 L 11261332 1149 CPe_l 15638520 1 #00753F R 15724520 1550 unk 19111930 0 #ACAAC8 L 14194703 1361 unk 15679484 1 #00753F L 15610387 1525 unk 16629757 1 #E55560 L -1 -1 MBNB A axon_output axon_input dendrite_output dendrite_input 7766016 402.0 73.0 27.0 200.0 7790597 283.0 17.0 0.0 0.0 18833414 315.0 40.0 0.0 0.0 15564807 117.0 14.0 0.0 0.0 17383431 147.0 11.0 48.0 47.0 ... ... ... ... ... 3882998 104.0 7.0 1.0 21.0 15638520 155.0 24.0 0.0 0.0 19111930 0.0 0.0 0.0 194.0 15679484 116.0 5.0 0.0 0.0 16629757 199.0 76.0 34.0 67.0 [3549 rows x 58 columns]","title":"Load the data into an adjacency frame"},{"location":"tutorials/maggot_examples/#sorting","text":"We can sort the adjacency matrix and metadata according to some attributes. For example, alphabetically by name: sorted_af = af . sort_values ( \"name\" , axis = \"both\" ) print ( sorted_af . row_objects . head () . iloc [:, : 5 ]) name neurons \\ 7753261 (dda E3 or dda A)_a1l_JMpair2 False 3486867 130729_SFO Cand 42a-42b_OSN_IN1 left True 5478818 130729_SFO Cand 42a-42b_OSN_IN1 right True 7527710 13a ORN left False 4073353 13a ORN right False paper_clustered_neurons left right 7753261 False True False 3486867 True True False 5478818 True False True 7527710 True True False 4073353 True False True ... or by the amount of incoming synapses onto the dendrite: sorted_af = af . sort_values ( \"dendrite_input\" , axis = \"both\" , ascending = False ) print ( sorted_af . row_objects . head ()[[ \"name\" , \"dendrite_input\" ]]) name dendrite_input 8980589 MBE18 right 1481.0 16223537 MBE18 left 1282.0 8198238 broad T2 right 1201.0 5030808 keystone left 1129.0 6557581 broad T3 right 1127.0 In any case, the adjacency matrix is always sorted the same way as the metadata. from graspologic.plot import adjplot # adjplot(af.data, plot_type=\"scattermap\", sizes=(1, 1)) # adjplot(sorted_af.data, plot_type=\"scattermap\", sizes=(1, 1)) /Users/bpedigo/JHU_code/neuropull/neuropull/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html from .autonotebook import tqdm as notebook_tqdm","title":"Sorting"},{"location":"tutorials/maggot_examples/#filtering-and-subsetting","text":"We can filter the adjacency matrix and metadata according to some attributes. For example, we could select only the nodes in the left hemisphere. query_af = af . query ( \"hemisphere == 'L'\" , axis = \"both\" ) print ( query_af ) AdjacencyFrame with shape: (1772, 1772) Source node features: 58 Target node features: 58 Note that since the adjacency frame is just a thin wrapper around pandas DataFrames, we can use all the usual pandas methods to filter the data. For example, we can select only the nodes that are in the left hemisphere and have a dendrite input greater than some threshold. query_af = af . query ( \"hemisphere == 'L' and dendrite_input > 100\" , axis = \"both\" ) print ( query_af ) AdjacencyFrame with shape: (608, 608) Source node features: 58 Target node features: 58 We can also select a non-induced subgraph: that is, a set of edges that go from one set of nodes to a potentially different set of target nodes. Here, we select the connections from the left hemisphere to the right hemisphere. query_af = af . query ( \"hemisphere == 'L'\" , axis = 0 ) . query ( \"hemisphere == 'R'\" , axis = 1 ) print ( query_af . source_nodes [ \"hemisphere\" ]) print ( query_af . target_nodes [ \"hemisphere\" ]) 7766016 L 7790597 L 17383431 L 7782409 L 14434314 L .. 11067379 L 3882998 L 19111930 L 15679484 L 16629757 L Name: hemisphere, Length: 1772, dtype: object 18833414 R 15564807 R 15458316 R 11714576 R 10133525 R .. 15564782 R 12787696 R 15589362 R 2637812 R 15638520 R Name: hemisphere, Length: 1775, dtype: object","title":"Filtering and subsetting"},{"location":"tutorials/maggot_examples/#grouping","text":"Rather than selecting groups of nodes (like, say, the left hemisphere) one at a time, it is often convenient to subselect the entire network based on some column. First, let's remove a couple of nodes which are in the center (not on left or right). af = af . query ( \"hemisphere != 'C'\" , axis = \"both\" ) Then, let's do a grouping operation. groupby = af . groupby ( \"hemisphere\" , axis = \"both\" ) groupby <neuropull.graph.base_frame.FrameGroupBy at 0x13d1fc880> Much like in pandas, this returns a GroupBy object, which can be iterated over. for name , subframe in groupby : print ( name ) print ( subframe ) ('L', 'L') AdjacencyFrame with shape: (1772, 1772) Source node features: 58 Target node features: 58 ('L', 'R') AdjacencyFrame with shape: (1772, 1775) Source node features: 58 Target node features: 58 ('R', 'L') AdjacencyFrame with shape: (1775, 1772) Source node features: 58 Target node features: 58 ('R', 'R') AdjacencyFrame with shape: (1775, 1775) Source node features: 58 Target node features: 58 We could, for instance, compute the number of possible edges in each group. def possible_edges ( frame ): return frame . shape [ 0 ] * frame . shape [ 1 ] for name , subframe in groupby : print ( name ) print ( \"Possible edges:\" , possible_edges ( subframe )) print () ('L', 'L') Possible edges: 3139984 ('L', 'R') Possible edges: 3145300 ('R', 'L') Possible edges: 3145300 ('R', 'R') Possible edges: 3150625 Just like in pandas, since this pattern is so common, we can use the apply function of the FrameGroupBy object to apply a function to each group and collate the results. groupby . apply ( possible_edges ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 3139984 3145300 R 3145300 3150625 If we want to use a function which operates on the underlying adjacency matrix only, we can just modify the function slightly. def matrix_sum ( frame ): return np . sum ( frame . data ) groupby . apply ( matrix_sum ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 123720.0 58409.0 R 54783.0 136440.0 However, shorthand for this is to just pass the data=True flag to the apply function, and then a function which operates on the adjacency matrix will work. groupby . apply ( np . sum , data = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 123720.0 58409.0 R 54783.0 136440.0 Another example is using this to compute the probability of an edge existing between each group. def density ( data ): return np . count_nonzero ( data ) / data . size groupby . apply ( density , data = True ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } L R L 0.01238 0.006056 R 0.00588 0.013209 pair_counts = af . source_nodes [ \"pair_id\" ] . value_counts () af . source_nodes [ \"pair_count\" ] = af . source_nodes [ \"pair_id\" ] . map ( pair_counts ) == 2 af . target_nodes [ \"pair_count\" ] = af . target_nodes [ \"pair_id\" ] . map ( pair_counts ) == 2 pair_af = af . query ( \"pair_count\" , axis = \"both\" ) pair_af = pair_af . sort_values ([ \"hemisphere\" , \"pair_id\" ], axis = \"both\" ) pair_af = pair_af . set_index ([ \"hemisphere\" , \"pair_id\" ]) print ( pair_af . source_nodes . iloc [: 5 , : 5 ]) name neurons \\ hemisphere pair_id L 2 BAmas12 contra left; Interneuron--35 in total True 3 DALd bushy left; DALd_l 2 True 4 DALd_l 3 True 5 BU ; DALd 4_left True 6 UNK brain ascending left True paper_clustered_neurons left right hemisphere pair_id L 2 True True False 3 True True False 4 True True False 5 True True False 6 True True False print ( pair_af . source_nodes . loc [ \"L\" ] . iloc [: 5 , : 5 ]) name neurons \\ pair_id 2 BAmas12 contra left; Interneuron--35 in total True 3 DALd bushy left; DALd_l 2 True 4 DALd_l 3 True 5 BU ; DALd 4_left True 6 UNK brain ascending left True paper_clustered_neurons left right pair_id 2 True True False 3 True True False 4 True True False 5 True True False 6 True True False print ( pair_af . source_nodes . loc [ \"R\" ] . iloc [: 5 , : 5 ]) name neurons paper_clustered_neurons \\ pair_id 2 BAmas12 contra right True True 3 DALd bushy right; DALd_r 5 Review True True 4 DALd_r 10 10276162 - JL True True 5 BU ; DALd 4_right True True 6 UNK brain ascending right True True left right pair_id 2 False True 3 False True 4 False True 5 False True 6 False True for hemisphere , side_af in pair_af . groupby ( \"hemisphere\" , axis = \"both\" ): print ( hemisphere ) print ( side_af ) ('L', 'L') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57 ('L', 'R') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57 ('R', 'L') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57 ('R', 'R') AdjacencyFrame with shape: (1634, 1634) Source node features: 57 Target node features: 57","title":"Grouping"}]}